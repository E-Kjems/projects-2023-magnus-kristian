{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR PROJECT TITLE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note the following:** \n",
    "> 1. This is *not* meant to be an example of an actual **model analysis project**, just an example of how to structure such a project.\n",
    "> 1. Remember the general advice on structuring and commenting your code\n",
    "> 1. The `modelproject.py` file includes a function which could be used multiple times in this notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and set magics:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of project: Cournot duopoly\n",
    "\n",
    "Equations:\n",
    "Aggregate demand\n",
    "Individual profit functions (used to find aggregate supply)\n",
    "\n",
    "Analytical solution:\n",
    "Find individual response functions\n",
    "\n",
    "Grid search:\n",
    "Try different outputs and check that supply equates demand.\n",
    "\n",
    "Extensions:\n",
    "Add more periods -> Easier to collude\n",
    "Add more firms -> Harder to collude\n",
    "Vary delta -> see how collusion is harder to sustain\n",
    "Vary homogeniety of products\n",
    "Vary costs - draw from distribution\n",
    "Entry/exit\n",
    "Simulate model over time - plot quantity/price for different shocks to parameters\n",
    "\n",
    "\n",
    "Set up as class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sm\n",
    "\n",
    "from scipy import optimize\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# autoreload modules when code is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# local modules\n",
    "import modelproject"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demand and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining symbolic variables for the optimization problem\n",
    "x = sm.symbols('x')  # Symbolic variable representing x\n",
    "x_rest = sm.symbols('x_rest')  # Symbolic variable representing x_rest\n",
    "\n",
    "# Defining the objective function\n",
    "objective = (1 - x - x_rest - c) * x\n",
    "\n",
    "# Taking the first derivative of the objective function w.r.t x\n",
    "obj_dif = sm.diff(objective, x)\n",
    "\n",
    "# Converting the symbolic expression for the derivative into a callable function\n",
    "best = sm.lambdify(args=(x, x_rest), expr=obj_dif)\n",
    "\n",
    "# Taking the second derivative of the objective function w.r.t x\n",
    "best_dif = sm.diff(obj_dif, x)\n",
    "\n",
    "# Converting the symbolic expression for the second derivative into a callable function\n",
    "jac_x = sm.lambdify(args=(x, x_rest), expr=best_dif)\n",
    "\n",
    "# Taking the second derivative of the objective function w.r.t x_rest\n",
    "best_dif = sm.diff(obj_dif, x_rest)\n",
    "\n",
    "# Converting the symbolic expression for the second derivative into a callable function\n",
    "jac_x_rest = sm.lambdify(args=(x, x_rest), expr=best_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " message: The solution converged.\n",
      " success: True\n",
      "  status: 1\n",
      "     fun: [ 1.110e-16  3.331e-16 ...  1.110e-16  1.110e-16]\n",
      "       x: [ 9.901e-03  9.901e-03 ...  9.901e-03  9.901e-03]\n",
      "    nfev: 3\n",
      "    njev: 1\n",
      "    fjac: [[-1.971e-01 -9.853e-02 ... -9.853e-02 -9.853e-02]\n",
      "           [ 6.951e-01 -7.157e-01 ... -6.882e-03 -6.882e-03]\n",
      "           ...\n",
      "           [ 1.005e-02  1.005e-02 ... -9.950e-01 -9.952e-05]\n",
      "           [ 9.951e-03  9.951e-03 ...  9.951e-03 -9.951e-01]]\n",
      "       r: [ 1.015e+01  1.005e+01 ...  1.015e-02  1.005e+00]\n",
      "     qtf: [ 9.714e-15 -6.594e-16 ... -7.142e-17 -7.071e-17]\n",
      "\n",
      "x = [0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099\n",
      " 0.00990099 0.00990099 0.00990099 0.00990099] , h(x) = [1.11022302e-16 3.33066907e-16 2.22044605e-16 2.22044605e-16\n",
      " 2.22044605e-16 2.22044605e-16 2.22044605e-16 3.33066907e-16\n",
      " 3.33066907e-16 4.44089210e-16 2.22044605e-16 3.33066907e-16\n",
      " 2.22044605e-16 2.22044605e-16 2.22044605e-16 3.33066907e-16\n",
      " 2.22044605e-16 2.22044605e-16 2.22044605e-16 2.22044605e-16\n",
      " 4.44089210e-16 3.33066907e-16 3.33066907e-16 4.44089210e-16\n",
      " 1.11022302e-16 3.33066907e-16 4.44089210e-16 1.11022302e-16\n",
      " 2.22044605e-16 2.22044605e-16 2.22044605e-16 2.22044605e-16\n",
      " 2.22044605e-16 2.22044605e-16 3.33066907e-16 2.22044605e-16\n",
      " 2.22044605e-16 2.22044605e-16 4.44089210e-16 2.22044605e-16\n",
      " 4.44089210e-16 3.33066907e-16 2.22044605e-16 2.22044605e-16\n",
      " 3.33066907e-16 3.33066907e-16 3.33066907e-16 2.22044605e-16\n",
      " 3.33066907e-16 3.33066907e-16 2.22044605e-16 2.22044605e-16\n",
      " 2.22044605e-16 3.33066907e-16 1.11022302e-16 2.22044605e-16\n",
      " 2.22044605e-16 1.11022302e-16 2.22044605e-16 3.33066907e-16\n",
      " 1.11022302e-16 2.22044605e-16 2.22044605e-16 2.22044605e-16\n",
      " 2.22044605e-16 2.22044605e-16 2.22044605e-16 2.22044605e-16\n",
      " 3.33066907e-16 4.44089210e-16 2.22044605e-16 2.22044605e-16\n",
      " 2.22044605e-16 2.22044605e-16 2.22044605e-16 2.22044605e-16\n",
      " 3.33066907e-16 2.22044605e-16 2.22044605e-16 1.11022302e-16\n",
      " 2.22044605e-16 1.11022302e-16 2.22044605e-16 1.11022302e-16\n",
      " 3.33066907e-16 1.11022302e-16 2.22044605e-16 1.11022302e-16\n",
      " 2.22044605e-16 2.22044605e-16 1.11022302e-16 2.22044605e-16\n",
      " 2.22044605e-16 2.22044605e-16 2.22044605e-16 1.11022302e-16\n",
      " 2.22044605e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16]\n"
     ]
    }
   ],
   "source": [
    "# Setting up the parameters for the optimization problem\n",
    "c = 0  # Constant value for the objective function\n",
    "N = 100  # Number of variables\n",
    "\n",
    "# Setting up the initial values for x_rest\n",
    "x_rest = np.zeros(N)\n",
    "\n",
    "# Defining the function to be optimized\n",
    "def h(x):\n",
    "    y = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        # Evaluating the first derivative of the objective function at x[i]\n",
    "        y[i] = best(x[i], sum(x) - x[i])\n",
    "    return y\n",
    "\n",
    "# Defining the Jacobian of the function to be optimized\n",
    "def hp(x):\n",
    "    y = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                # Evaluating the second derivative of the objective function w.r.t x[i]\n",
    "                y[i,j] = jac_x(x[i], sum(x) - x[i])\n",
    "            else:\n",
    "                # Evaluating the second derivative of the objective function w.r.t x_rest[i]\n",
    "                y[i,j] = jac_x_rest(x[i], sum(x) - x[i])\n",
    "    return y\n",
    "\n",
    "# Setting up the initial values for x\n",
    "x0 = np.array(x_rest)\n",
    "\n",
    "# Solving the optimization problem using scipy.optimize.root() function\n",
    "result = optimize.root(h, x0, jac=hp)\n",
    "\n",
    "# Printing the results\n",
    "print(result)\n",
    "print('\\nx =', result.x, ', h(x) =', h(result.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: Solution found.\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: -0.03999999999999998\n",
       "       x: 0.20000000000000012\n",
       "     nit: 6\n",
       "    nfev: 6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"axes.grid\":True,\"grid.color\":\"black\",\"grid.alpha\":\"0.25\",\"grid.linestyle\":\"--\"})\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy import optimize\n",
    "\n",
    "#Identical good\n",
    "c=1\n",
    "\n",
    "def inv_demand(x,x_rest):\n",
    "    return 1-x-x_rest\n",
    "\n",
    "#Identical production functions\n",
    "def cost(x,c=0.1):\n",
    "    if x == 0:\n",
    "        cost_value = 0\n",
    "    else:\n",
    "        cost_value = c*x\n",
    "    return cost_value\n",
    "\n",
    "def revenue(x,x_rest):\n",
    "    return inv_demand(x,x_rest)*x\n",
    "\n",
    "def profit(x,x_rest,c):\n",
    "    return revenue(x,x_rest)-cost(x,c)\n",
    "\n",
    "def solve(x_rest,c):\n",
    "    obj= lambda x: -profit(x,x_rest,c)\n",
    "    solution = optimize.minimize_scalar(obj, method='bounded', bounds=(0,1))\n",
    "    return solution\n",
    "\n",
    "solve(0.1,0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write out the model in equations here.** \n",
    "\n",
    "Make sure you explain well the purpose of the model and comment so that other students who may not have seen it before can follow.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your model allows for an analytical solution, you should provide here.\n",
    "\n",
    "You may use Sympy for this. Then you can characterize the solution as a function of a parameter of the model.\n",
    "\n",
    "To characterize the solution, first derive a steady state equation as a function of a parameter using Sympy.solve and then turn it into a python function by Sympy.lambdify. See the lecture notes for details. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always solve a model numerically. \n",
    "\n",
    "Define first the set of parameters you need. \n",
    "\n",
    "Then choose one of the optimization algorithms that we have gone through in the lectures based on what you think is most fitting for your model.\n",
    "\n",
    "Are there any problems with convergence? Does the model converge for all starting values? Make a lot of testing to figure these things out. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make detailed vizualizations of how your model changes with parameter values. \n",
    "\n",
    "Try to make an extension of the model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add concise conclusion. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "47ef90cdf3004d3f859f1fb202523c65c07ba7c22eefd261b181f4744e2d0403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
