{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR PROJECT TITLE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note the following:** \n",
    "> 1. This is *not* meant to be an example of an actual **model analysis project**, just an example of how to structure such a project.\n",
    "> 1. Remember the general advice on structuring and commenting your code\n",
    "> 1. The `modelproject.py` file includes a function which could be used multiple times in this notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and set magics:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of project: Cournot duopoly\n",
    "\n",
    "Equations:\n",
    "Aggregate demand\n",
    "Individual profit functions (used to find aggregate supply)\n",
    "\n",
    "Analytical solution:\n",
    "Find individual response functions\n",
    "\n",
    "Grid search:\n",
    "Try different outputs and check that supply equates demand.\n",
    "\n",
    "Extensions:\n",
    "Add more periods -> Easier to collude (påkrævet)\n",
    "Vary delta -> see how collusion is harder to sustain\n",
    "Vary homogeniety of products\n",
    "Vary costs - draw from distribution (påkrævet)\n",
    "Entry/exit \n",
    "Simulate model over time - plot quantity/price for different shocks to parameters (Corona-stød?)\n",
    "\n",
    "Sjove plot (påkrævet)\n",
    "Set up as class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sm\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import optimize\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# autoreload modules when code is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# local modules\n",
    "import modelproject"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demand and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "import sympy as sm\n",
    "\n",
    "# Defining symbolic variables for the optimization problem\n",
    "x = sm.symbols('x')  # Symbolic variable representing x\n",
    "x_rest = sm.symbols('x_rest')  # Symbolic variable representing x_rest\n",
    "c=sm.symbols('c')\n",
    "\n",
    "# Defining the objective function\n",
    "#penalty = 100  # choose a suitable penalty value\n",
    "objective = (1 - x - x_rest - c) * x\n",
    "objective_lambd=sm.lambdify(args=(x,x_rest,c),expr=objective)\n",
    "\n",
    "# Taking the first derivative of the objective function w.r.t x\n",
    "obj_dif = sm.diff(objective, x)\n",
    "# Converting the symbolic expression for the derivative into a callable function\n",
    "best = sm.lambdify(args=(x, x_rest,c), expr=obj_dif)\n",
    "\n",
    "# Taking the second derivative of the objective function w.r.t x\n",
    "best_dif = sm.diff(obj_dif, x)\n",
    "\n",
    "# Converting the symbolic expression for the second derivative into a callable function\n",
    "jac_x = sm.lambdify(args=(x, x_rest), expr=best_dif)\n",
    "\n",
    "# Taking the second derivative of the objective function w.r.t x_rest\n",
    "best_dif = sm.diff(obj_dif, x_rest)\n",
    "\n",
    "# Converting the symbolic expression for the second derivative into a callable function\n",
    "jac_x_rest = sm.lambdify(args=(x, x_rest), expr=best_dif)\n",
    "\n",
    "# Define the constraint that x should be greater than or equal to 0\n",
    "#constraint = sm.Max(x, 0)\n",
    "\n",
    "# Modify the objective to include the constraint\n",
    "#modified_objective = sm.Piecewise((penalty*(-x), x < 0), (objective_orig*constraint, True))\n",
    "\n",
    "# Convert the modified objective to a callable function\n",
    "#modified_objective_lambd = sm.lambdify(args=(x, x_rest, c), expr=modified_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to be optimized\n",
    "def h(x):\n",
    "    y = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        # Evaluating the first derivative of the objective function at x[i]\n",
    "        #c_rand = norm.rvs(loc=0, scale=0.001)\n",
    "        y[i] = best(x[i], sum(x) - x[i], c_vec[i])\n",
    "    return y\n",
    "\n",
    "# Defining the Jacobian of the function to be optimized\n",
    "def hp(x):\n",
    "    y = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                # Evaluating the second derivative of the objective function w.r.t x[i]\n",
    "                y[i,j] = jac_x(x[i], sum(x) - x[i])\n",
    "            else:\n",
    "                # Evaluating the second derivative of the objective function w.r.t x_rest[i]\n",
    "                y[i,j] = jac_x_rest(x[i], sum(x) - x[i])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " message: The solution converged.\n",
      " success: True\n",
      "  status: 1\n",
      "     fun: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "            0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00]\n",
      "       x: [ 2.356e-01 -9.866e-02 -9.571e-01  5.590e-01  5.589e-01\n",
      "           -2.092e+00  5.590e-01  5.587e-01  5.589e-01  5.589e-01]\n",
      "    nfev: 6\n",
      "    njev: 1\n",
      "    fjac: [[-5.384e-01 -2.710e-01 ... -2.848e-01 -2.848e-01]\n",
      "           [ 4.091e-01 -8.724e-01 ...  5.156e-02  5.156e-02]\n",
      "           ...\n",
      "           [ 1.338e-01  1.479e-02 ... -9.436e-01 -2.529e-02]\n",
      "           [ 1.143e-01  1.263e-02 ...  1.240e-01 -9.514e-01]]\n",
      "       r: [ 3.944e+00  1.889e+00 ...  1.705e-01  1.075e+00]\n",
      "     qtf: [-5.879e-16  5.792e-17 -1.281e-16 -8.431e-17 -6.204e-17\n",
      "           -1.258e-16  8.841e-17 -5.568e-17 -4.589e-17 -3.918e-17]\n",
      "\n",
      "x = [ 0.23563928 -0.09865545 -0.957052    0.55896013  0.55890795 -2.09227514\n",
      "  0.55896013  0.5587318   0.55887398  0.55894919] \n",
      "h(x) = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      "sum(x) = 0.4410398699888224 \n",
      "marginal cost= [3.23320851e-01 6.57615585e-01 1.51601213e+00 9.44495240e-10\n",
      " 5.21765403e-05 2.65123527e+00 4.91579878e-10] \n",
      "profit= [0.05552587 0.0097329  0.91594852 0.31243643 0.3123781  4.37761527\n",
      " 0.31243643 0.31218123 0.31234012 0.3124242 ]\n"
     ]
    }
   ],
   "source": [
    "#Initial løsning\n",
    "# Setting up the parameters for the optimization problem\n",
    "N = 10  # Number of variables\n",
    "\n",
    "# Setting up the initial values for x_rest\n",
    "x_rest = np.zeros(N)\n",
    "\n",
    "np.random.seed(2000)\n",
    "c_vec = np.random.normal(loc=0,scale=0.50,size=N)\n",
    "c_vec=c_vec**8\n",
    "\n",
    "# Setting up the initial values for x\n",
    "x0 = np.array(x_rest)\n",
    "\n",
    "# Solving the optimization problem using scipy.optimize.root() function\n",
    "result = optimize.root(h, x0, jac=hp)\n",
    "\n",
    "profit=objective_lambd(result.x,np.sum(result.x)-result.x,c_vec)\n",
    "# Printing the results\n",
    "print(result)\n",
    "print('\\nx =', result.x[0:10], '\\nh(x) =', h(result.x)[0:10], '\\nsum(x) =', sum(result.x), '\\nmarginal cost=',c_vec[0:7],'\\nprofit=', profit[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " message: The solution converged.\n",
      " success: True\n",
      "  status: 1\n",
      "     fun: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "            0.000e+00]\n",
      "       x: [ 1.429e-01  1.429e-01  1.429e-01  1.427e-01  1.428e-01\n",
      "            1.429e-01]\n",
      "    nfev: 4\n",
      "    njev: 1\n",
      "    fjac: [[-7.559e-01 -3.779e-01 ...  9.218e-03  9.218e-03]\n",
      "           [ 3.219e-01 -5.312e-01 ... -5.498e-01 -5.498e-01]\n",
      "           ...\n",
      "           [-4.032e-01  2.643e-01 ... -7.650e-01  2.065e-01]\n",
      "           [-3.812e-01  2.498e-01 ...  2.498e-01 -7.778e-01]]\n",
      "       r: [ 2.646e+00  2.246e+00 ...  5.774e-02  1.028e+00]\n",
      "     qtf: [ 1.678e-16 -7.148e-17 -2.467e-17 -1.538e-17  8.953e-17\n",
      "            8.464e-17]\n",
      "\n",
      "x = [0.14291108 0.14285891 0.14291108 0.14268276 0.14282493 0.14290015] \n",
      "h(x) = [0. 0. 0. 0. 0. 0.] \n",
      "sum(x) = 0.8570889148316649 \n",
      "marginal cost= [9.44495240e-10 5.21765403e-05 4.91579878e-10 2.28328866e-04\n",
      " 8.61513706e-05 1.09379658e-05] \n",
      "profit= [0.02042358 0.02040867 0.02042358 0.02035837 0.02039896 0.02042045]\n"
     ]
    }
   ],
   "source": [
    "#Anden del af løsningen (som skal køres k gange)\n",
    "\n",
    "nonneg_x=result.x>=0\n",
    "varlist_new=[\"x_rest\", \"c_vec\", \"x0\"]\n",
    "for var_name in varlist_new:\n",
    "    var = globals()[var_name]\n",
    "    globals()[var_name+'_new'] = var[nonneg_x]\n",
    "\n",
    "N_new=sum(nonneg_x)\n",
    "N_new\n",
    "\n",
    "# Setting up the parameters for the optimization problem\n",
    "#c = 0.001  # Constant value for the objective function\n",
    "N = N_new # Number of variables\n",
    "\n",
    "# Setting up the initial values for x_rest\n",
    "x_rest = x_rest_new\n",
    "\n",
    "np.random.seed(2000)\n",
    "c_vec = c_vec_new\n",
    "\n",
    "# Setting up the initial values for x\n",
    "x0 = x0_new\n",
    "\n",
    "# Solving the optimization problem using scipy.optimize.root() function\n",
    "result = optimize.root(h, x0_new, jac=hp)\n",
    "\n",
    "profit=objective_lambd(result.x,np.sum(result.x)-result.x,c_vec)\n",
    "# Printing the results\n",
    "print(result)\n",
    "print('\\nx =', result.x[0:10], '\\nh(x) =', h(result.x)[0:10], '\\nsum(x) =', sum(result.x), '\\nmarginal cost=',c_vec[0:7],'\\nprofit=', profit[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " message: The solution converged.\n",
      " success: True\n",
      "  status: 1\n",
      "     fun: [ 0.000e+00  1.110e-16 ...  1.110e-16  1.110e-16]\n",
      "       x: [ 5.957e-03  5.905e-03 ...  5.943e-03  3.863e-03]\n",
      "    nfev: 7\n",
      "    njev: 1\n",
      "    fjac: [[-1.997e-01 -7.533e-02 ... -7.533e-02 -7.533e-02]\n",
      "           [ 6.274e-01 -7.709e-01 ... -8.114e-03 -8.114e-03]\n",
      "           ...\n",
      "           [-5.309e-03 -6.594e-03 ...  9.970e-01  4.494e-04]\n",
      "           [ 5.272e-03  6.548e-03 ...  6.460e-03 -9.970e-01]]\n",
      "       r: [ 8.043e+00  6.700e+00 ... -6.954e-03  1.003e+00]\n",
      "     qtf: [ 9.239e-15  5.761e-16 ...  1.847e-17 -1.834e-17]\n",
      "\n",
      "x = [0.00595725 0.00590508 0.00595725 0.00572893 0.0058711  0.00594632\n",
      " 0.00525515 0.00595706 0.00595723 0.00595725] \n",
      "h(x) = [0.00000000e+00 1.11022302e-16 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.11022302e-16\n",
      " 0.00000000e+00 1.11022302e-16] \n",
      "sum(x) = 0.9940427450405963 \n",
      "marginal cost= [9.44495240e-10 5.21765403e-05 4.91579878e-10 2.28328866e-04\n",
      " 8.61513706e-05 1.09379658e-05 7.02102390e-04] \n",
      "profit= [3.54888754e-05 3.48699511e-05 3.54888808e-05 3.28205942e-05\n",
      " 3.44698574e-05 3.53586858e-05 2.76166285e-05 3.54865077e-05\n",
      " 3.54886223e-05 3.54888555e-05] \n",
      "N_firms = 181\n"
     ]
    }
   ],
   "source": [
    "#Initial løsning\n",
    "# Setting up the parameters for the optimization problem\n",
    "N = 250  # Number of variables\n",
    "\n",
    "# Setting up the initial values for x_rest\n",
    "x_rest = np.zeros(N)\n",
    "\n",
    "np.random.seed(2000)\n",
    "c_vec = np.random.normal(loc=0,scale=0.50,size=N)\n",
    "c_vec=c_vec**8\n",
    "\n",
    "# Setting up the initial values for x\n",
    "x0 = np.array(x_rest)\n",
    "\n",
    "# Solving the optimization problem using scipy.optimize.root() function\n",
    "result = optimize.root(h, x0, jac=hp)\n",
    "\n",
    "nonneg_x=result.x>=0\n",
    "varlist_new=[\"x_rest\", \"c_vec\", \"x0\"]\n",
    "for var_name in varlist_new:\n",
    "    var = globals()[var_name]\n",
    "    globals()[var_name+'_new'] = var[nonneg_x]\n",
    "\n",
    "N_new=sum(nonneg_x)\n",
    "while not all(nonneg_x):\n",
    "    # Setting up the parameters for the optimization problem\n",
    "    #c = 0.001  # Constant value for the objective function\n",
    "    N = N_new # Number of variables\n",
    "\n",
    "    # Setting up the initial values for x_rest\n",
    "    x_rest = x_rest_new\n",
    "\n",
    "    np.random.seed(2000)\n",
    "    c_vec = c_vec_new\n",
    "\n",
    "    # Setting up the initial values for x\n",
    "    x0 = x0_new\n",
    "\n",
    "    # Solving the optimization problem using scipy.optimize.root() function\n",
    "    result = optimize.root(h, x0_new, jac=hp)\n",
    "\n",
    "    nonneg_x=result.x>=0\n",
    "    varlist_new=[\"x_rest\", \"c_vec\", \"x0\"]\n",
    "    for var_name in varlist_new:\n",
    "        var = globals()[var_name]\n",
    "        globals()[var_name+'_new'] = var[nonneg_x]\n",
    "\n",
    "    N_new=sum(nonneg_x)\n",
    "\n",
    "profit=objective_lambd(result.x,np.sum(result.x)-result.x,c_vec)\n",
    "# Printing the results\n",
    "print(result)\n",
    "print('\\nx =', result.x[0:10], '\\nh(x) =', h(result.x)[0:10], '\\nsum(x) =', sum(result.x), '\\nmarginal cost=',c_vec[0:7],'\\nprofit=', profit[0:10],'\\nN_firms =',N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write out the model in equations here.** \n",
    "\n",
    "Make sure you explain well the purpose of the model and comment so that other students who may not have seen it before can follow.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your model allows for an analytical solution, you should provide here.\n",
    "\n",
    "You may use Sympy for this. Then you can characterize the solution as a function of a parameter of the model.\n",
    "\n",
    "To characterize the solution, first derive a steady state equation as a function of a parameter using Sympy.solve and then turn it into a python function by Sympy.lambdify. See the lecture notes for details. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always solve a model numerically. \n",
    "\n",
    "Define first the set of parameters you need. \n",
    "\n",
    "Then choose one of the optimization algorithms that we have gone through in the lectures based on what you think is most fitting for your model.\n",
    "\n",
    "Are there any problems with convergence? Does the model converge for all starting values? Make a lot of testing to figure these things out. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make detailed vizualizations of how your model changes with parameter values. \n",
    "\n",
    "Try to make an extension of the model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add concise conclusion. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "47ef90cdf3004d3f859f1fb202523c65c07ba7c22eefd261b181f4744e2d0403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
